Hello,

Appologies for the delay. Hot weather and childcare and building work in my house have meant I have not been able to get to this.

Thank you for your responses. I hope I have addressed them satisfactorally below. Given the imporance of ethical research - including Open Science and Open Data: making data publicly available wherever possible for transparency and reproducability - I have gone into some depth. If you see still see any problems, I would be happy to resolve them.

You will notice that attached to this email are some data files. One is fake example data, the others are anonymised data from a previous experiment. I make reference to these in the discussion below.


Student Participants
--------------------

Original form:
> Will any of the participants be students?

My answer:
> Due to the recruitment process, I have no way of knowing.

Ethics response:
> So, in section 4, Recruitment of participants the final answer is
> incorrect as according to the above paper Prolific has pre-selection
> and researchers are able to ask questions which may be part of the
> survey to select the correct type of participant for their study. Thus
> to say that I have no way of knowing can be considered either
> unethical or the researcher is not using the tool to their best
> advantage.

You are referring to the original form as this question does not appear on the updated form that I submitted with my revisions.

Firstly, my interpretation of this question what that it was asking if any of the participants were students _at the University of York_, over whom 1) it is likely that many studies approved using that form will largely sample, 2) the University could reasonably have a duty of care, and 3) researchers from the University are more likely to have a coersive power over. There is no filter that I can apply that will tell me if a participant is a student at the University of York. The closest I could get is to try to infer from Postcode of Work or Postcode of Residence in combination with student status - but still that would not separate out York St John students, and would be unreliable. 

I see that the question may refer to students in general. However, if so, it makes no difference to my answer, for the following reasons:

I can apply a filter to determine if somone has student status (i.e. answers "yes" to "Are you a student?"). Thus I could choose to exclude all students. Or I could choose to include only students. In this way, I could therefore run the study in such a way that I knew that all of my participants were students or that none of my participants were students. I could not run a study where I know which participants were students, using Prolific's filtering tools.

It would harm the external validity of my experiment were I to filter in either of these ways. To only include students would be to voluntarily make my research subject the common criticism that students are over-sampled in psychology and related disciplines. To exclude students would be to exclude a subset of the population who might respond differently to game-based studies, due to demographic and cultural reasons (e.g. most students are 18-21 and will have grown up playing digital games).

So, while I _could_ run a study using Prolific in which I would be able to know whether my participants were (all) students or (all) not, that would be a different (and worse) study to the one I am running. Following the study design that I am proposing, with the population I wish to sample, I cannot know whether or not some, all, or none of the participants delivered to me are students, using Prolific's filters.

And all this is, to me, somewhat moot anyway, because even if I did know. What would I do with that information? There is no way it would affect the delivery of the experiment. Nor would I be interested in recording that information for research purposes. If the data had a bearing on anything I was doing, I could include it in the pre-test questionnaire. Unless I would use the data, recording such information would violate Principle (c) of the GDPR - Data minimisation.

So, in summary, in the study I am submitting for ethical approval there remains no way for me to know whether any of my participants are students, whether at the University of York or otherwise, unless I asked the question in the pre-test questionnaire which, I believe, would be unnecessary and irrelevant (and thus violate the GDPR). Another way of phrasing this is to answer the question: "Will any of the participants be students?" with "Maybe or maybe not, but if so I don't know which ones."


Data Storage
------------

Ethics response:
> I would like them to confirm that the home desktop is the departmental
> provided one and that there is no identifiable material stored on the
> laptop.

In my updated form submitted by email 30 Jul 2020 I updated this point based on the previous feedback. In that email I said: 

> I have updated my procedure so that I will download the data to the
> University filestore and anonymise it on the University network via a
> VPN. It will only be analysed on my personal desktop computer in the
> anonymous form in which it will be published.

The updated form read:

> The data will be downloaded to the University computer network
> filestore and anonymised there.

To reiterate, the only computers identifiable data will be stored on will be the server it is collected on and University-managed computers. I will access them remotely to do the anonymisation using the University VPN from home, because of being unable to access in person due to the pandemic.

When the data is in its anonymous publishable form, it is irrelevant where it is analysed, securely or not.


Public Task
-----------

Ethics reponse:
>Sorry David - I think you also need to look at the ICO definition of a
> "public task" re your GDPR argument.
> https://ico.org.uk/for-organisations/guide-to-data-protection/guide-to-the-general-data-protection-regulation-gdpr/lawful-basis-for-processing/public-task/

My use of the public task justification comes from this page "GDPR Compliant Research" (https://www.york.ac.uk/records-management/dp/guidance/gdprcompliantresearch/):

> The majority of University research involving personal data will be
> conducted under Article 6 (1) (e) of the GDPR i.e.
> 
> > Processing is necessary for the performance of a task carried out
> > in the public interest

[...]

> Under the GDPR, the University will not rely on consent as the legal
> basis for undertaking research. However, in line with best ethical
> practice and in order to demonstrate compliance with the common law
> duty of confidentiality, the University will, typically, obtain consent
> from data subjects to participate in research.

My interpretation is that, I need to ensure participants consent to the experiment for ethical reasons (hence providing information through the study description), but it is not necessary to record this consent explicitly in the data for data protection reasons (especially as it can be inferred that a participant was shown the study description by the presence of a Prolific ID in the data).

If you were referring to a particular part of the linked document that I have overlooked, please let me know.


Anonymisation and Composite Data
--------------------------------

Ethics reponse:
> Your comment about anonymisation is, in theory, correct - but there
> are arguments about composite data still being identifiable even if
> the obvious personal identifiers have been removed.

Yes. If you have such an argument, I would like to hear it. The anonymisation process that I will apply does indeed render the data sufficiently anonymous that, to my best understanding, it no longer counts as personal data under the GDPR. Part of this is that there is no data set that plausibly exists that renders the anonymous data indentifiable.

Also note the following:

> In some circumstances there may be a slight hypothetical possibility
> that someone might be able to reconstruct the data in such a way that
> identifies the individual. However, this is not necessarily sufficient
> to make the individual identifiable in terms of GDPR. You must consider
> all the factors at stake.  (https://ico.org.uk/for-organisations/guide-to-data-protection/guide-to-the-general-data-protection-regulation-gdpr/key-definitions/what-is-personal-data/)

In my updated submission (30 Jul 2020) with the new form, I mention the potential data sets the original data can be recombined with in section 2.5. In section 2.6 I state how it will be anonymised so that it is no longer identifiable:

> The data will be fully anonymised as soon as possible after it is
> downloaded.  This will be done by removing participant’s Prolific ID,
> and disassociating duration and gender from the rest of the data. The
> non anonymised data will then be deleted. It will then be impossible
> even with Prolific’s or another data set to identify individuals.
> This data will be published for research transparency on the Open
> Science Framework (https://osf.io)

To clarify the data I will be releasing after anonymisation (as best as I can before I actually run the experiment), I will detail it here.

1. a CSV file containing experiment condition and duration.
2. a CSV file containing age and gender
3. a JSON file containing   
    1. the version of the game that was presented
    2. experiment condition
    3. language (english - other responses are removed from the data set during processing as I cannot use them - just used to double check Prolific's filtering)
    4. gaming frequency (5 point likert scale "almost never" -> "every day")
    5. responses to the Intrinsic Motivation Inventory - Enjoyment subscale (a set of 7 questions asking how much they enjoyed the activity)
    6. each move taken in the game (a sentence of three words, e.g. "big red square", "triangle yellow empty")
    7. time taken to make each move, in seconds
    8. grammaticality judgements of a list of 6 simple sentence fragments.
    
Note that the order of files 1, 2 and 3 are each randomised, so they cannot be associated with each other.

I will address them in turn.

1. This information could potentially be associated with an individual by someone with Prolific's dataset. By comparing their log of duration and correlating it with mine, they could pick out a row. If they do so, the only information they get is the experimental condition performed.

Under the GDPR (https://ico.org.uk/for-organisations/guide-to-data-protection/guide-to-the-general-data-protection-regulation-gdpr/key-definitions/what-is-personal-data/, see the section "What is the meaning of ‘relates to’?"):

> "information must ‘relate to’ the identifiable individual to be
> personal data [...] Data can reference an identifiable individual
> and not be personal data about that individual, as the information
> does not relate to them." 

The condition the experiment was run in is chosen randomly, it encodes no information about the individual, thus it does not relate to the individual.

2. This information could potentially be associated with an individual by someone with Prolific's dataset. By comparing their logs and the age and gender of the participants they delivered, they could identify the age and gender of that person: precicely what they already knew. Gender alone would subset the data, but unlikely identify an individual. Age alone might identify a single row, but would tell you only their gender. This would only be useful if you somehow knew that a person of a particular age performed the experiment, but not their gender. It is hard to imagine such a situation occouring (a slight hypothetical possibility, in the words of the GDPR), and if it does there is minimal impact.

3.  1. Data 1 is the same for all participants.
    2. There is no data that can identify 2: Prolific knows nothing about the experimental conditions, and it is currently even decided in-browser, so there is no difference in the network traffic.
    3. Data 3 is the same for all participants.
    4. For data 4, if you knew a participant performed the experiment and you had their response to this question (not included in Prolific's dataset) then you could narrow down to a subset of the participants, but only to the extent that the answer is reliable over time.
    5-6. For data 5, and 6 you would need a model that can predict these things reliably from another source of data, which is fanciful.
    7. It may be thought that summed together for a participant this could give a proxy measure of duration. However, this data measures only time elapsed during gameplay. The length of gameplay is controlled so all participants play for the same length of time (8 minutes). Thus this value has no necessary correlation with experiment duration data. (This value will actually be lower than 8 minutes, because it does not include the time elapsed between levels of the game, which is included in the 8 minute calculation)
    8. This data relates to adjective ordering, which is standardised within English. Given all the published data will be from individuals with a first language of English, there will be significant overlap between participants in responses for this question. Excluding for noise and dishonest responses, there are vary few truthful reponse sets. 

The only remaining ways I can think of to identify an individual would be to have intercepted the data before anonymisation, or for Prolific (or someone with their database) to perform a study on the same set of people with the intention of correlating responses to my data. Recall that a "slight hypothetical possibility that someone might be able to reconstruct the data in such a way that identifies the individual [...] is not necessarily sufficient to make the individual identifiable in terms of GDPR" (from quote from ICO above).

If you can spot a way in which it is posible to identify an individual from this data in conjunction with another data set (in a way that is not just - in the words of the GDPR - a slight hypothetical possibility), please let me know.

I will, of course, reassess all of my assumptions in light of the actual data when I see it. If I discover any previously unexpected potential for identifying an individual, I will address it immediately. For example, with my last experiment, I split the data into three files as described above to ensure duration, gender and age couldn't be used to identify an individual.

I have attached an (example, fake) data record showing the data I will be keeping on each participant before anonymisation. I have also attached the anonymised data from a very similar previous experiment to give an idea of what the final format will look like (though the data collected there was slightly different).


Please let me know if there is anything I can help to clarify about the above, if there was anything I missed or misinterpreted, or if you have any other questions about my study.

Many thanks,
David